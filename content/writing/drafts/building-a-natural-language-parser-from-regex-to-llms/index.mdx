---
title: "Building a Natural Language Parser: From Regex to LLMs"
date: 2025-11-15
summary: "How I evaluated four approaches to natural language parsing."
tags: [ai, llm, product, engineering, case-study]
draft: true
---

# Building a Natural Language Parser: From Regex to LLMs
**How I evaluated four different approaches to natural language parsing — and why accuracy won.**

From my initial scoping and development work on TripThreads my hypothesis was that enabling natural language would unlock the use of the app by enabling users to add expenses and travel plans quickly thereby reducing friction and improving accessibality. 

But implementing a parser that works across messy real-world input is harder than it looks.

I explored four different solutions
— classic regex 
- deterministic NLP 
- on-device LLMs 
- hosted LLM
To evaluate the results I created a test suite of 90 typical inputs covering typical use cases that my app would cover. This covered basic inputs and in the future test I intend to cover edge cases and more user testing to ensure coverage.

This is a summary of how each approach worked, where it broke, and what ultimately made it into production.

---

# Why Natural Language Input Mattered

For TripThreads, input speed is everything. Most travel apps make you fill in structured forms:

- amount
- currency
- description
- date
- participants
- split rules

If users can instead type things like:

- "Dinner €60 split 4 ways"
- "Flight to Paris Monday 9am"
- "Alice paid $120 for hotel, Bob owes 40%"

…and the platform just takes care of extracting the necessary information, parsing it iand storing it in the backend, the experience becomes dramatically faster and more enjoyable.

---

# Version 1 — Regex Parsing
**Fast, simple… and brittle.**

Regex was the obvious first step: fast, deterministic, easy to run on-device and not resource intensive. But in practice, it only worked for perfect input.

### Problems

- Breaks on typos
- Order of phrases varies
- Many valid expressions can't be captured with simple patterns
- Currency formats differ across regions
- No understanding of context

### Accuracy

**42/90 correct (~46%)**

Great for textbook cases; terrible for real-world use.

---

# Version 2 — Deterministic NLP Parser
**A more sophisticated rules-based system with reinforcement learning.**

This parser used:

- tokenization
- custom heuristics
- chrono-node for date extraction
- rules for currency, amounts, and split types

It incorporated a reinforcement learning mechanism so that users woud be able to provide feedback to the system by correcting and errors. These corrections would be scored and they would be used to decide which parser rule to be followed the next time a similar phrase was seen. 

### Strengths

- Fully offline
- Extremely fast (&lt;10ms)
- Deterministic
- Easy to test

### Weaknesses

Real-world travel messages are too varied:

- "Taxi 45 with John owes me later"
- "Marriott 15–20 Dec €200"
- "Museum tmr afternoon"
- "Brunch yesterday 30 each"

Even with this Rule complexity grew without improving overall reliability.

### Accuracy

**55/90 (~61%)**

Better — but still not good enough to be a flagship feature.
Perhaps if we expanded the reinforcement learning data set we might get more success with this method, but I was trying to move quickly with the development of this platform.

---

# Version 3 — On-Device LLMs
**Promising accuracy, unusably slow.**

To improve accuracy while minimizing cost I tried running small LLMs locally:

- **Phi-3-mini**
- **Mistral 7B**
- **Llama 3.2**

These were run on a **MacBook Air (CPU-only)** using **Ollama**, occasionally packaged via Docker.

### Results

- Good flexibility
- Better accuracy than deterministic parsing
- Solid privacy guarantees
- No external server dependency

But the performance was unacceptable.

### Latency

- **Over 30 seconds per request** (CPU-only, no quantization)

For an interactive UI, this was a deal-breaker.

### Accuracy

**83/90 (~92%)**

---

# Version 4 — Hosted LLM (GPT-4o-mini)
**The first approach that actually felt "right."**

I integrated **GPT-4o-mini** through a server-side API route with structured JSON output. User text was sanitised (removed any PII info) and was processed by the model. The output was provided in the form of classification data and intent mapping and was stored as a JSON blob.

This version delivered:

- high accuracy
- robust parsing of dates, currencies, amounts
- handling of typo-ridden or ambiguous input
- ability to parse "dual" items (hotel = expense + stay)
- significantly reduced maintenance

### Latency

**500–1500ms**
Acceptable for a preview → confirm workflow.

### Accuracy

**85/90 (~94%)**

A dramatic improvement over all other approaches.

### Cost

On calculating a model for a typical user, we find that the costs are negligible:

- ~$0.00005 per parse
- ~10,000 parses/month → ~$0.50
- ~100,000 parses/month → ~$5.00

This is more than adequate for our use case. 

---

# Comparison Table — Accuracy

| Parser | Score | Notes |
|--------|--------|-------|
| Regex | 42/90 | Only works on clean, simple inputs |
| Deterministic NLP | 55/90 | Rules don't scale with input complexity |
| On-Device LLM | 83/90 | Accurate enough, but too slow |
| GPT-4o-mini | 85/90 | Best by a wide margin |

---

# Comparison Table — Latency

| Parser | Latency |
|--------|----------|
| Regex | &lt;10ms |
| Deterministic NLP | &lt;10ms |
| On-Device LLM (no quant.) | **&gt;30,000ms** |
| GPT-4o-mini | 500–1500ms |

---

# Comparison Table — Cost

| Parser | Cost per parse |
|--------|----------------|
| Regex | Free |
| Deterministic NLP | Free |
| On-Device LLM | Free (hardware bottleneck) |
| GPT-4o-mini | ~$0.00005 |

---

# Final Decision

I chose **GPT-4o-mini** because:

- **Accuracy was the defining feature**
  Natural language input is the core differentiator — correctness is non-negotiable.
- **Maintenance is minimal**
  No more managing dozens of regex rules or heuristics.
- **Latency is acceptable**
  Especially within a preview flow.
- **Cost is extremely low**
  Even at high usage, total cost remains trivial.
- **Handles real human language**
  Typos, synonyms, ambiguous phrasing, and relative dates — all handled gracefully.

---

# Architecture Overview

```text
User Input
   ↓
AI Parser (GPT-4o-mini)
   ↓
Structured JSON
   ↓
UI Preview
   ↓
User Confirms
   ↓
Database Save
```

- Server-side only (API key protected)
- Realtime UI feedback
- Supports expenses, itineraries, and hybrid items
- Easy integration with fuzzy participant matching and multi-payer logic

---

## What I Learned

Building this parser touched every layer of the stack — model selection, UX, infrastructure, and product trade-offs.

Key lessons:

- Accuracy beats speed when the feature is core to the product. A fast but wrong parser creates more frustration than value.
- Rule-based systems don't scale to real-world language. The long tail of expressions is endless.
- On-device LLMs aren't ready (at least without adequate computing power). Without hardware acceleration or quantization, latency is unacceptable.
- Testing at scale matters. Ninety test cases across multiple parser versions made the trade-offs clear.
- Think like a systems PM. Evaluate accuracy, latency, cost, privacy, and UX — not just the model itself.

---

## What's Next

I'm exploring a hybrid approach:

1. Client-side deterministic parsing for simple cases
2. LLM parsing for everything else
3. Result caching to improve speed and reduce cost
4. Offline fallback using deterministic parsing
5. User feedback loops to improve model prompts over time
6. Over time as we collect sufficient user inputs we can develop our own model to transfer off the API.

This combination will balance speed, reliability, and cost while keeping the experience seamless.

---

If you want to go deeper into the implementation or see the full test suite, feel free to reach out.
